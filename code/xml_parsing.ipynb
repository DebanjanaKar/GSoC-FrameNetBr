{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_text(text, start, end):\n",
    "    #extracting words from the text given the start and end indices\n",
    "    str_idx_map = list(enumerate(text))\n",
    "    string = \"\"\n",
    "    for i in range(len(str_idx_map)):\n",
    "        #print(start, x[i])\n",
    "        if start in str_idx_map[i]:\n",
    "            string = string + str_idx_map[i][1]\n",
    "            #print(str_idx_map[i][1], string)\n",
    "            if start < end :\n",
    "                start = start + 1\n",
    "    return string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = {}\n",
    "lu = {}\n",
    "pos_tag = {}\n",
    "frame_name = {}\n",
    "frame_element = {}\n",
    "frame_element_lu = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "path = \"../ted_annotation_data/\"\n",
    "import os \n",
    "annotation = {}\n",
    "languages = []\n",
    "count = 0\n",
    "\n",
    "for file in os.listdir(path): \n",
    "    print(\"-------------------------------------------------------------------------------\") \n",
    "    filename = path + file \n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    lang = (file.split(\"_\")[2]).split(\".\")[0]\n",
    "    if lang not in languages:\n",
    "        languages.append(lang)\n",
    "        \n",
    "    #creating separate dumps of the features\n",
    "    if lang not in text:\n",
    "        text[lang] = []\n",
    "    \n",
    "    if lang not in lu:\n",
    "        lu[lang] = []\n",
    "    \n",
    "    if lang not in pos_tag:\n",
    "        pos_tag[lang] = []\n",
    "        \n",
    "    if lang not in frame_name:\n",
    "        frame_name[lang] = []\n",
    "        \n",
    "    if lang not in frame_element:\n",
    "        frame_element[lang] = []\n",
    "        \n",
    "    if lang not in frame_element_lu:\n",
    "        frame_element_lu[lang] = []\n",
    "    \n",
    "    for child in root:\n",
    "        if child.tag == \"header\":\n",
    "            continue\n",
    "        #key = sentence id + language\n",
    "        key = child.attrib[\"ID\"] + \"_\" + lang\n",
    "        annotation[key] = {}\n",
    "        for child1 in child:\n",
    "            if child1.tag == 'text':\n",
    "                annotation[key][\"text\"] = child1.text\n",
    "                text[lang].append((child1.text, child.attrib[\"ID\"] ))\n",
    "            else:\n",
    "                if \"lu\" not in annotation[key]:\n",
    "                        annotation[key][\"lu\"] = [child1.attrib[\"luName\"].split(\".\")[0] ]\n",
    "                else:\n",
    "                        annotation[key][\"lu\"].append(child1.attrib[\"luName\"].split(\".\")[0]) \n",
    "                #lu dump - contains the lu, corresponding luID and sentence ID\n",
    "                lu[lang].append((child1.attrib[\"luName\"].split(\".\")[0], child1.attrib[\"luID\"], child.attrib[\"ID\"]))\n",
    "                \n",
    "                \n",
    "                \n",
    "                if \"pos_tag\" not in annotation[key]:\n",
    "                    annotation[key][\"pos_tag\"] = [child1.attrib[\"luName\"].split(\".\")[1]]\n",
    "                else:\n",
    "                    annotation[key][\"pos_tag\"].append(child1.attrib[\"luName\"].split(\".\")[1])\n",
    "                \n",
    "                #pos_tag dump\n",
    "                pos_tag[lang].append((child1.attrib[\"luName\"].split(\".\")[1], child1.attrib[\"luID\"], child.attrib[\"ID\"]))\n",
    "                \n",
    "                \n",
    "                \n",
    "                if \"frame_name\" not in annotation[key]:\n",
    "                    annotation[key][\"frame_name\"] = [child1.attrib[\"frameName\"]]\n",
    "                else:\n",
    "                    annotation[key][\"frame_name\"].append(child1.attrib[\"frameName\"])\n",
    "                #frame dump\n",
    "                frame_name[lang].append(child1.attrib[\"frameName\"])\n",
    "                \n",
    "            for child2 in child1:\n",
    "                if child2.attrib['name'] == 'target':\n",
    "                    continue\n",
    "                #print(child2.tag, child2.attrib)\n",
    "                else:\n",
    "                    if \"frame_element\" not in annotation[key]:\n",
    "                        annotation[key][\"frame_element\"] = []\n",
    "                        annotation[key][\"frame_element_lu\"] = []\n",
    "                    fe = []\n",
    "                    fe_lu = []\n",
    "                    for child3 in child2:\n",
    "                        fe.append(child3.attrib[\"name\"].replace(\"\\n\", \"\"))\n",
    "                        #frame element dump\n",
    "                        frame_element[lang].append(child3.attrib[\"name\"].replace(\"\\n\", \"\"))\n",
    "                        \n",
    "                        fe_lu.append(index_to_text(annotation[key][\"text\"].replace(\"\\n\", \"\"), int(child3.attrib[\"start\"]), int(child3.attrib[\"end\"])))\n",
    "                        #frame element lu dump\n",
    "                        frame_element_lu[lang].append((index_to_text(annotation[key][\"text\"].replace(\"\\n\", \"\"), int(child3.attrib[\"start\"]), int(child3.attrib[\"end\"])), child3.attrib['ID'], child.attrib[\"ID\"]))\n",
    "                    \n",
    "                    annotation[key][\"frame_element\"].append(fe)\n",
    "                    annotation[key][\"frame_element_lu\"].append(fe_lu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"annotation\" dictionary is arranged as such : \n",
    "* **Annotation** { s_id : \tFName : [ 1, 2, 3 ...]\n",
    "\t\t\tLU : [1, 2, 3 ... ]\n",
    "\t\t\tPOS_FN : [1, 2, 3 â€¦. ]\n",
    "\t\t\tFE : [ 1( a, b, ..), 2( a, b, ..), ... ]\n",
    "\t\t\tFE_LU : [ 1( a, b, ..), 2( a, b, ..), ... ]\n",
    "\t\t\tText : \n",
    "\t} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"../resources/annotated_data.pickle\", \"wb\") as pkl_out:\n",
    "    pkl.dump(annotation, pkl_out)\n",
    "    pkl.dump(text, pkl_out)\n",
    "    pkl.dump(lu, pkl_out)\n",
    "    pkl.dump(pos_tag, pkl_out)\n",
    "    pkl.dump(frame_name, pkl_out)\n",
    "    pkl.dump(frame_element, pkl_out)\n",
    "    pkl.dump(frame_element_lu, pkl_out)\n",
    "    pkl.dump(languages, pkl_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc19",
   "language": "python",
   "name": "gsoc19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
